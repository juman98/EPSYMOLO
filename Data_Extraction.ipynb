{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEj7l2Kumk78",
        "outputId": "124a5c39-e31f-411c-d7b0-6b5c3fbfdeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvtFDox0mqGx"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Power_flow_data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def concatenate_csv_files_in_folder(folder_path):\n",
        "    # Create an empty DataFrame\n",
        "    concatenated_df = pd.DataFrame()\n",
        "\n",
        "    # Loop through all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Check if the file is a CSV\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            # Read the CSV file and concatenate it to the DataFrame\n",
        "            df = pd.read_csv(file_path)\n",
        "            concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
        "\n",
        "    return concatenated_df\n",
        "\n",
        "# Replace with your actual folder path\n",
        "#folder_path = 'your_actual_path_to_folder_with_csv_files'\n",
        "final_dataframe = concatenate_csv_files_in_folder(folder_path)\n",
        "print(final_dataframe.head()) # Display the first few rows of the final DataFrame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jCYFgFSVv9i",
        "outputId": "8a73d952-4cc3-4150-91ec-b6c5957ddd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp DayOfWeek  PowerLineID  PowerFlowValue\n",
            "0  2010-07-01 18:05:00  Thursday         1815          -26.00\n",
            "1  2010-07-01 18:05:00  Thursday         1687          148.54\n",
            "2  2010-07-01 18:05:00  Thursday         1567          -38.46\n",
            "3  2010-07-01 18:05:00  Thursday          733           35.51\n",
            "4  2010-07-01 18:05:00  Thursday         1688         -136.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/content/drive/MyDrive/Power_flow_data/Data_Merged.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "final_dataframe.to_csv(output_file_path, index=False) # Set index=False if you don't want to save the index in the CSV\n",
        "\n",
        "print(f\"DataFrame saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMxfSrSoWg6C",
        "outputId": "8f533dca-4b56-4091-88e1-d0e14c392f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to /content/drive/MyDrive/Power_flow_data/Data_Merged.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yrIu-d8rc1Z"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/2018_power_flow_data/adapt/X2.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S71GCQ9I_pBd",
        "outputId": "fe5bd7ee-882c-4854-a441-5359faaa34a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group: X\n",
            "Dataset: X/type\n",
            "Group: X/value\n",
            "Group: X/value/X\n",
            "Dataset: X/value/X/type\n",
            "Dataset: X/value/X/value\n",
            "Group: X/value/aux\n",
            "Dataset: X/value/aux/type\n",
            "Dataset: X/value/aux/value\n",
            "Group: X/value/hat\n",
            "Dataset: X/value/hat/type\n",
            "Group: X/value/hat/value\n",
            "Group: X/value/hat/value/X\n",
            "Dataset: X/value/hat/value/X/type\n",
            "Dataset: X/value/hat/value/X/value\n",
            "Group: X/value/hat/value/t\n",
            "Dataset: X/value/hat/value/t/type\n",
            "Dataset: X/value/hat/value/t/value\n",
            "Group: X/value/metadata\n",
            "Dataset: X/value/metadata/type\n",
            "Dataset: X/value/metadata/value\n",
            "Group: X/value/t\n",
            "Dataset: X/value/t/type\n",
            "Dataset: X/value/t/value\n"
          ]
        }
      ],
      "source": [
        "h5_file = h5py.File(file_path, 'r')\n",
        "\n",
        "# List all groups and datasets within the file\n",
        "def print_hdf5_items(name, obj):\n",
        "    if isinstance(obj, h5py.Group):\n",
        "        print(f\"Group: {name}\")\n",
        "    if isinstance(obj, h5py.Dataset):\n",
        "        print(f\"Dataset: {name}\")\n",
        "\n",
        "h5_file.visititems(print_hdf5_items)\n",
        "h5_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BB1XQ6Ckd2Z",
        "outputId": "db725e31-5b14-401b-c814-84ba1ff73956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Name: /X/value/X/value\n",
            "Dataset Shape: (12, 1916, 1)\n",
            "Dataset Data Type: float32\n",
            "Dataset Chunk Size: None\n",
            "Data Preview:\n",
            "[[[354.97]\n",
            "  [-52.18]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]\n",
            "\n",
            " [[384.86]\n",
            "  [-39.87]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]\n",
            "\n",
            " [[382.49]\n",
            "  [-36.12]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[378.38]\n",
            "  [-41.71]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]\n",
            "\n",
            " [[371.61]\n",
            "  [-40.53]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]\n",
            "\n",
            " [[351.87]\n",
            "  [-49.37]\n",
            "  [  0.  ]\n",
            "  ...\n",
            "  [  0.  ]\n",
            "  [  0.  ]\n",
            "  [  0.  ]]]\n"
          ]
        }
      ],
      "source": [
        "# Open the HDF5 file\n",
        "h5_file = h5py.File('/content/drive/MyDrive/2018_power_flow_data/adapt/X1.h5','r')\n",
        "\n",
        "# Access the first dataset (\"X/type\")\n",
        "first_dataset = h5_file['X/value/X/value']\n",
        "# Inspect the dataset properties\n",
        "print(\"Dataset Name:\", first_dataset.name)\n",
        "print(\"Dataset Shape:\", first_dataset.shape)\n",
        "print(\"Dataset Data Type:\", first_dataset.dtype)\n",
        "print(\"Dataset Chunk Size:\", first_dataset.chunks)  # Only available if the dataset is chunked\n",
        "\n",
        "# Retrieve the data from the dataset\n",
        "data = first_dataset[()]\n",
        "print(\"Data Preview:\")\n",
        "print(data[:10])  # Display the first 10 elements, adjust as needed\n",
        "\n",
        "# Close the file when you're done\n",
        "h5_file.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L15S7bGojnmA"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsByXCxXNhdL",
        "outputId": "9c99bd6f-4e0f-498b-db1b-25618d4a880c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File X5.h5 has a different shape: (164, 1916, 1)\n",
            "File X2.h5 has a different shape: (1317, 1916, 1)\n",
            "File X17.h5 has a different shape: (1120, 1916, 1)\n",
            "File X38.h5 has a different shape: (2604, 1916, 1)\n",
            "File X35.h5 has a different shape: (258, 1916, 1)\n",
            "File X62.h5 has a different shape: (872, 1916, 1)\n",
            "File X23.h5 has a different shape: (1480, 1916, 1)\n",
            "File X50.h5 has a different shape: (280, 1916, 1)\n",
            "File X8.h5 has a different shape: (557, 1916, 1)\n",
            "File X68.h5 has a different shape: (1883, 1916, 1)\n",
            "File X44.h5 has a different shape: (483, 1916, 1)\n",
            "File X59.h5 has a different shape: (315, 1916, 1)\n",
            "File X32.h5 has a different shape: (3023, 1916, 1)\n",
            "File X47.h5 has a different shape: (894, 1916, 1)\n",
            "File X65.h5 has a different shape: (2059, 1916, 1)\n",
            "File X14.h5 has a different shape: (2127, 1916, 1)\n",
            "File X26.h5 has a different shape: (140, 1916, 1)\n",
            "File X41.h5 has a different shape: (673, 1916, 1)\n",
            "File X11.h5 has a different shape: (904, 1916, 1)\n",
            "File X29.h5 has a different shape: (806, 1916, 1)\n",
            "File X53.h5 has a different shape: (199, 1916, 1)\n",
            "File X20.h5 has a different shape: (1138, 1916, 1)\n",
            "File X56.h5 has a different shape: (971, 1916, 1)\n",
            "The following files have a different shape than expected:\n",
            "X5.h5\n",
            "X2.h5\n",
            "X17.h5\n",
            "X38.h5\n",
            "X35.h5\n",
            "X62.h5\n",
            "X23.h5\n",
            "X50.h5\n",
            "X8.h5\n",
            "X68.h5\n",
            "X44.h5\n",
            "X59.h5\n",
            "X32.h5\n",
            "X47.h5\n",
            "X65.h5\n",
            "X14.h5\n",
            "X26.h5\n",
            "X41.h5\n",
            "X11.h5\n",
            "X29.h5\n",
            "X53.h5\n",
            "X20.h5\n",
            "X56.h5\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import os\n",
        "\n",
        "# Set the directory where your .h5 files are located\n",
        "directory = '/content/drive/My Drive/2018_power_flow_data/adapt'\n",
        "\n",
        "# The expected shape\n",
        "expected_shape = (12, 1916, 1)\n",
        "\n",
        "# List to hold the names of files that do not match the expected shape\n",
        "files_with_different_shape = []\n",
        "\n",
        "# Loop through each file in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".h5\"):  # Check only .h5 files\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        with h5py.File(file_path, 'r') as h5_file:\n",
        "            # Access the dataset\n",
        "            dataset = h5_file['X/value/X/value']\n",
        "            # Check the shape of the dataset\n",
        "            if dataset.shape != expected_shape:\n",
        "                files_with_different_shape.append(filename)\n",
        "                print(f\"File {filename} has a different shape: {dataset.shape}\")\n",
        "\n",
        "# Check if any files had a different shape\n",
        "if files_with_different_shape:\n",
        "    print(\"The following files have a different shape than expected:\")\n",
        "    for fname in files_with_different_shape:\n",
        "        print(fname)\n",
        "else:\n",
        "    print(\"All files have the expected shape.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7h817RwNL7v",
        "outputId": "659c18be-bf92-4dfc-8d2f-ccd5d489cc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2009-07-07 20:53:20+00:00\n"
          ]
        }
      ],
      "source": [
        "import pytz\n",
        "\n",
        "# Example Unix timestamp\n",
        "unix_timestamp = 1.247e+9\n",
        "\n",
        "# Convert to datetime\n",
        "human_readable_date = pd.to_datetime(unix_timestamp, unit='s',utc=True)\n",
        "\n",
        "print(human_readable_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsOcVZuBOFUS",
        "outputId": "c08da29d-8852-4548-bce3-283610e250ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2010-07-01 11:00:00-05:00\n"
          ]
        }
      ],
      "source": [
        "# Example Unix timestamp\n",
        "unix_timestamp = 1.278e+9\n",
        "\n",
        "# Convert to UTC datetime\n",
        "utc_datetime = pd.to_datetime(unix_timestamp, unit='s', utc=True)\n",
        "\n",
        "# Convert from UTC to the specified time zone\n",
        "# Replace 'GOSAT' with the actual time zone name\n",
        "timezone = 'EST'\n",
        "localized_datetime = utc_datetime.tz_convert(timezone)\n",
        "\n",
        "print(localized_datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_9u9JiTJeP5",
        "outputId": "ffd25417-ea6f-404b-b9ad-e70d8967dfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw Timestamps Sample: [1.2780075e+09 1.2780078e+09 1.2780081e+09 1.2780084e+09 1.2780087e+09]\n",
            "             Timestamp  PowerLineID  PowerFlowValue\n",
            "36 2010-07-01 18:05:00            3      504.899994\n",
            "37 2010-07-01 18:10:00            3      465.290009\n",
            "38 2010-07-01 18:15:00            3      481.130005\n",
            "39 2010-07-01 18:20:00            3      490.679993\n",
            "40 2010-07-01 18:25:00            3      487.970001\n",
            "41 2010-07-01 18:30:00            3      477.600006\n",
            "42 2010-07-01 18:35:00            3      485.829987\n",
            "43 2010-07-01 18:40:00            3      462.010010\n",
            "44 2010-07-01 18:45:00            3      460.100006\n",
            "45 2010-07-01 18:50:00            3      459.079987\n",
            "46 2010-07-01 18:55:00            3      434.109985\n",
            "47 2010-07-01 19:00:00            3      505.690002\n"
          ]
        }
      ],
      "source": [
        "# Load HDF5 file\n",
        "with h5py.File(file_path, 'r') as file:\n",
        "    # Access the datasets\n",
        "    records = file['X/value/X/value'][:]\n",
        "    timestamps = file['X/value/t/value'][:]\n",
        "    print(\"Raw Timestamps Sample:\", timestamps.flatten()[:5])  # Prints the first 10 raw timestamps\n",
        "    # Convert timestamps to datetime\n",
        "    timestamps_converted = pd.to_datetime(timestamps.flatten(), unit='s')\n",
        "\n",
        "    # Reshape the records array to align with timestamps\n",
        "    records_reshaped = records.reshape(-1, records.shape[1])  # (number_of_timestamps, number_of_power_lines)\n",
        "\n",
        "    # Create DataFrame for each power line's record with timestamps\n",
        "    list_dfs = []\n",
        "    for i in range(records_reshaped.shape[1]):  # iterate over power lines\n",
        "        df_power_line = pd.DataFrame({\n",
        "            'Timestamp': timestamps_converted,\n",
        "            'PowerLineID': i,\n",
        "            'PowerFlowValue': records_reshaped[:, i]\n",
        "        })\n",
        "        list_dfs.append(df_power_line)\n",
        "\n",
        "    # Combine all individual DataFrames into one\n",
        "    df_merged = pd.concat(list_dfs, ignore_index=True)\n",
        "\n",
        "    # Filter for PowerLineID = 0\n",
        "    df_filtered = df_merged[df_merged['PowerLineID'] == 3]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(df_filtered)\n",
        "#df_filtered[(df_filtered['Timestamp'] >= '2010-07-02 00:00:00') & (df_filtered['Timestamp'] < '2010-07-03 00:00:00')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yug9-3jjO4k0",
        "outputId": "e5f88290-5891-42ce-ea66-8e0e34ca78c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Timestamp  PowerLineID  PowerFlowValue\n",
            "47540892 2010-07-01 18:05:00          890       46.900002\n",
            "47548908 2010-07-01 18:05:00         1558        0.000000\n",
            "47551452 2010-07-01 18:05:00         1770      -41.330002\n",
            "47530356 2010-07-01 18:05:00           12      594.729980\n",
            "47534460 2010-07-01 18:05:00          354     -150.630005\n",
            "...                      ...          ...             ...\n",
            "33160093 2010-09-25 22:15:00          409       92.970001\n",
            "32986857 2010-09-25 22:15:00          317     -176.279999\n",
            "32909654 2010-09-25 22:15:00          276       56.799999\n",
            "34278595 2010-09-25 22:15:00         1003      143.960007\n",
            "33559289 2010-09-25 22:15:00          621       -5.440000\n",
            "\n",
            "[47553204 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Define the path to the folder containing the HDF5 files\n",
        "folder_path = '/content/drive/MyDrive/2018_power_flow_data/adapt/*.h5'  # Update this with your folder path\n",
        "# List to store DataFrames from each file\n",
        "all_dfs = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for file_path in glob.glob(folder_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        # Access the datasets\n",
        "        records = file['X/value/X/value'][:]\n",
        "        timestamps = file['X/value/t/value'][:]\n",
        "\n",
        "        # Convert timestamps to datetime\n",
        "        timestamps_converted = pd.to_datetime(timestamps.flatten(), unit='s')\n",
        "        # Get the day of the week for each timestamp\n",
        "        day_of_week = timestamps_converted.day_name()\n",
        "\n",
        "        # Reshape the records array to align with timestamps\n",
        "        records_reshaped = records.reshape(-1, records.shape[1])\n",
        "\n",
        "        # Create DataFrame for each power line's record with timestamps\n",
        "        list_dfs = []\n",
        "        for i in range(records_reshaped.shape[1]):\n",
        "            df_power_line = pd.DataFrame({\n",
        "                'Timestamp': timestamps_converted,\n",
        "                #'DayOfWeek': day_of_week,  # Add the day of the week here\n",
        "                'PowerLineID': i,\n",
        "                'PowerFlowValue': records_reshaped[:, i]\n",
        "            })\n",
        "            list_dfs.append(df_power_line)\n",
        "\n",
        "        # Combine all individual DataFrames into one and append to the main list\n",
        "        df_merged = pd.concat(list_dfs, ignore_index=True)\n",
        "        all_dfs.append(df_merged)\n",
        "\n",
        "# Concatenate all DataFrames from all files\n",
        "df_combined = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "# Sort the combined DataFrame by the 'Timestamp' column\n",
        "df_combined_sorted = df_combined.sort_values(by='Timestamp')\n",
        "\n",
        "# Optionally, filter for a specific PowerLineID (e.g., ID = 3)\n",
        "#df_filtered = df_combined_sorted[df_combined_sorted['PowerLineID'] == 125]\n",
        "\n",
        "print(df_combined_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivoted_combined_df = df_combined_sorted.pivot(index='Timestamp', columns='PowerLineID', values='PowerFlowValue')\n",
        "print(pivoted_combined_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlIBPXY_zoYj",
        "outputId": "cbd8b744-bdc5-40b1-a61e-a287799b91ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PowerLineID                0           1           2           3     \\\n",
            "Timestamp                                                             \n",
            "2010-07-01 18:05:00  342.600006  -72.300003    0.000000  504.899994   \n",
            "2010-07-01 18:10:00  340.519989  -77.459999    0.000000  465.290009   \n",
            "2010-07-01 18:15:00  332.220001  -84.269997    0.000000  481.130005   \n",
            "2010-07-01 18:20:00  323.000000  -74.360001    0.000000  490.679993   \n",
            "2010-07-01 18:25:00  302.429993  -88.839996    0.000000  487.970001   \n",
            "...                         ...         ...         ...         ...   \n",
            "2010-09-25 21:55:00  202.080002  -73.230003  362.640015  388.920013   \n",
            "2010-09-25 22:00:00  197.369995  -79.260002  371.399994  337.790009   \n",
            "2010-09-25 22:05:00  154.869995 -112.800003  383.239990  262.529999   \n",
            "2010-09-25 22:10:00  106.629997 -137.350006  382.660004  225.199997   \n",
            "2010-09-25 22:15:00  116.470001 -120.360001  389.750000  235.820007   \n",
            "\n",
            "PowerLineID                4           5           6           7     \\\n",
            "Timestamp                                                             \n",
            "2010-07-01 18:05:00  245.410004  762.429993  925.150024    0.000000   \n",
            "2010-07-01 18:10:00  244.770004  743.580017  911.150024    0.000000   \n",
            "2010-07-01 18:15:00  240.809998  752.510010  923.549988    0.000000   \n",
            "2010-07-01 18:20:00  236.600006  769.719971  937.260010    0.000000   \n",
            "2010-07-01 18:25:00  212.750000  773.739990  933.130005    0.000000   \n",
            "...                         ...         ...         ...         ...   \n",
            "2010-09-25 21:55:00  234.059998    0.000000    0.000000  516.130005   \n",
            "2010-09-25 22:00:00  231.679993    0.000000    0.000000  512.099976   \n",
            "2010-09-25 22:05:00  190.559998    0.000000    0.000000  533.960022   \n",
            "2010-09-25 22:10:00  137.610001    0.000000    0.000000  517.700012   \n",
            "2010-09-25 22:15:00  146.729996    0.000000    0.000000  505.450012   \n",
            "\n",
            "PowerLineID                8           9     ...  1906  1907  1908  1909  \\\n",
            "Timestamp                                    ...                           \n",
            "2010-07-01 18:05:00  618.489990  174.279999  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 18:10:00  619.239990  171.990005  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 18:15:00  622.340027  170.619995  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 18:20:00  577.380005  162.889999  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 18:25:00  577.349976  159.210007  ...   0.0   0.0   0.0   0.0   \n",
            "...                         ...         ...  ...   ...   ...   ...   ...   \n",
            "2010-09-25 21:55:00  519.929993  212.449997  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 22:00:00  515.869995  205.839996  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 22:05:00  537.900024  198.880005  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 22:10:00  521.520020  184.020004  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 22:15:00  509.179993  186.029999  ...   0.0   0.0   0.0   0.0   \n",
            "\n",
            "PowerLineID          1910  1911  1912  1913  1914  1915  \n",
            "Timestamp                                                \n",
            "2010-07-01 18:05:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 18:10:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 18:15:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 18:20:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 18:25:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "...                   ...   ...   ...   ...   ...   ...  \n",
            "2010-09-25 21:55:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 22:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 22:05:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 22:10:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 22:15:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[24819 rows x 1916 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Define the path to the folder containing the HDF5 files\n",
        "folder_path = '/content/drive/MyDrive/2018_power_flow_data/adapt/*.h5'  # Update this with your folder path\n",
        "# List to store DataFrames from each file\n",
        "all_dfs = []\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for file_path in glob.glob(folder_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        # Access the datasets\n",
        "        records = file['X/value/X/value'][:]\n",
        "        timestamps = file['X/value/t/value'][:]\n",
        "\n",
        "        # Convert timestamps to datetime\n",
        "        timestamps_converted = pd.to_datetime(timestamps.flatten(), unit='s')\n",
        "\n",
        "        # Reshape the records array to align with timestamps\n",
        "        records_reshaped = records.reshape(-1, records.shape[1])\n",
        "\n",
        "        # Create DataFrame for each power line's record with timestamps\n",
        "        list_dfs = []\n",
        "        for i in range(records_reshaped.shape[1]):\n",
        "            df_power_line = pd.DataFrame({\n",
        "                'Timestamp': timestamps_converted,\n",
        "                'PowerLineID': i,\n",
        "                'PowerFlowValue': records_reshaped[:, i]\n",
        "            })\n",
        "            list_dfs.append(df_power_line)\n",
        "\n",
        "        # Combine all individual DataFrames into one and append to the main list\n",
        "        df_merged = pd.concat(list_dfs, ignore_index=True)\n",
        "        all_dfs.append(df_merged)\n",
        "\n",
        "# Concatenate all DataFrames from all files\n",
        "df_combined = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "# Sort the combined DataFrame by the 'Timestamp' column\n",
        "df_combined_sorted = df_combined.sort_values(by='Timestamp')\n",
        "\n",
        "# Round down the 'Timestamp' to the nearest hour and group by 'PowerLineID' and 'Timestamp'\n",
        "df_combined_sorted['Timestamp'] = df_combined_sorted['Timestamp'].dt.floor('H')\n",
        "df_hourly_avg = df_combined_sorted.groupby(['PowerLineID', 'Timestamp']).mean().reset_index()\n",
        "\n",
        "print(df_hourly_avg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8UaVZ12bUx3",
        "outputId": "253608ac-abf1-4d56-d7bb-4bb19dbf3bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         PowerLineID           Timestamp  PowerFlowValue\n",
            "0                  0 2010-07-01 18:00:00      306.371826\n",
            "1                  0 2010-07-01 19:00:00      367.140015\n",
            "2                  0 2010-07-01 20:00:00      363.129150\n",
            "3                  0 2010-07-01 21:00:00      480.254150\n",
            "4                  0 2010-07-01 22:00:00      416.828339\n",
            "...              ...                 ...             ...\n",
            "3964199         1915 2010-09-25 18:00:00        0.000000\n",
            "3964200         1915 2010-09-25 19:00:00        0.000000\n",
            "3964201         1915 2010-09-25 20:00:00        0.000000\n",
            "3964202         1915 2010-09-25 21:00:00        0.000000\n",
            "3964203         1915 2010-09-25 22:00:00        0.000000\n",
            "\n",
            "[3964204 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivoted_df = df_hourly_avg.pivot(index='Timestamp', columns='PowerLineID', values='PowerFlowValue')\n",
        "print(pivoted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEb3muHTxf92",
        "outputId": "fdec90ed-f8d4-476c-f5a8-50e02d2948b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PowerLineID                0           1           2           3     \\\n",
            "Timestamp                                                             \n",
            "2010-07-01 18:00:00  306.371826  -89.693634    0.000000  473.518188   \n",
            "2010-07-01 19:00:00  367.140015  -45.134167    0.000000  592.751648   \n",
            "2010-07-01 20:00:00  363.129150  -34.750835    0.000000  608.714172   \n",
            "2010-07-01 21:00:00  480.254150   66.106667    0.000000  719.851624   \n",
            "2010-07-01 22:00:00  416.828339    7.810833    0.000000  566.283325   \n",
            "...                         ...         ...         ...         ...   \n",
            "2010-09-25 18:00:00  217.884171   -0.980000  316.674164  492.391632   \n",
            "2010-09-25 19:00:00  156.638336  -74.539162  283.223328  386.578339   \n",
            "2010-09-25 20:00:00  151.856674 -112.578331  317.991669  319.893341   \n",
            "2010-09-25 21:00:00  182.394165  -85.529999  355.242523  359.865845   \n",
            "2010-09-25 22:00:00  143.834991 -112.442505  381.762512  265.334991   \n",
            "\n",
            "PowerLineID                4           5            6           7     \\\n",
            "Timestamp                                                              \n",
            "2010-07-01 18:00:00  217.347275  777.257263   931.496338    0.000000   \n",
            "2010-07-01 19:00:00  291.790833  892.455017  1044.476685    0.000000   \n",
            "2010-07-01 20:00:00  302.004181  918.186707  1013.141663    0.000000   \n",
            "2010-07-01 21:00:00  413.255829  921.044189  1060.128296    0.000000   \n",
            "2010-07-01 22:00:00  323.291656  794.994141   994.043274    0.000000   \n",
            "...                         ...         ...          ...         ...   \n",
            "2010-09-25 18:00:00  254.119156    0.000000     0.000000  444.910004   \n",
            "2010-09-25 19:00:00  192.280014    0.000000     0.000000  460.611664   \n",
            "2010-09-25 20:00:00  183.755005    0.000000     0.000000  550.369141   \n",
            "2010-09-25 21:00:00  217.199173    0.000000     0.000000  528.499207   \n",
            "2010-09-25 22:00:00  176.644989    0.000000     0.000000  517.302490   \n",
            "\n",
            "PowerLineID                8           9     ...  1906  1907  1908  1909  \\\n",
            "Timestamp                                    ...                           \n",
            "2010-07-01 18:00:00  588.777283  161.773636  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 19:00:00  566.845032  176.975830  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 20:00:00  517.593323  156.959167  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 21:00:00  522.240051  185.203323  ...   0.0   0.0   0.0   0.0   \n",
            "2010-07-01 22:00:00  602.600830  185.570847  ...   0.0   0.0   0.0   0.0   \n",
            "...                         ...         ...  ...   ...   ...   ...   ...   \n",
            "2010-09-25 18:00:00  448.189972  243.880844  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 19:00:00  464.011688  222.385818  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 20:00:00  554.427490  218.578323  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 21:00:00  532.395813  215.206665  ...   0.0   0.0   0.0   0.0   \n",
            "2010-09-25 22:00:00  521.117493  193.692505  ...   0.0   0.0   0.0   0.0   \n",
            "\n",
            "PowerLineID          1910  1911  1912  1913  1914  1915  \n",
            "Timestamp                                                \n",
            "2010-07-01 18:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 19:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 20:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 21:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-07-01 22:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "...                   ...   ...   ...   ...   ...   ...  \n",
            "2010-09-25 18:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 19:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 20:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 21:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2010-09-25 22:00:00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[2069 rows x 1916 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW0LX0acXqZi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Assuming df_combined_sorted is your sorted DataFrame\n",
        "# Create a directory for the CSV files if it doesn't exist\n",
        "output_dir = '/content/drive/MyDrive/Power_flow_data_hourly'  # Update this with your desired path\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Group the DataFrame by the date part of the index\n",
        "grouped = df_combined_sorted.groupby(df_combined_sorted['Timestamp'].dt.date)\n",
        "\n",
        "# Iterate over each group, reset the index, and save to a separate CSV file\n",
        "for date, group in grouped:\n",
        "    group = group.reset_index()  # Reset the index to turn it into a column\n",
        "    file_name = f'{date}.csv'\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "    group.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grouped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIZPUWGO6iuH",
        "outputId": "de18bf10-174d-4ac5-9f40-d57ae61537f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x782e66c58460>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}